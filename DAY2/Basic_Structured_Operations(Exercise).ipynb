{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0vyTaRGOdmB"
      },
      "source": [
        "## Basic Structured Operations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2KpLHzVOdmE"
      },
      "source": [
        "### Step 1: Initialize PySpark Session\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "2Xue9qjMOdmE",
        "outputId": "5657c1b5-a544-4362-9219-3a4120a654b8"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, expr\n",
        "\n",
        "# Create a Spark session\n",
        "spark = SparkSession.builder.appName(\"day2\").getOrCreate()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCeSCVDKOdmG"
      },
      "source": [
        "### Step 2: Load the Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "QHmqfHtkOdmG"
      },
      "outputs": [],
      "source": [
        "# Load the Occupation dataset into a Spark DataFrame\n",
        "data_path = \"occupation.csv\"  # Replace with the actual path\n",
        "occupation = spark.read.csv(data_path, header=True, inferSchema=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "8629vMtbOdmG",
        "outputId": "80bc57c1-d3d3-49d8-c2d4-7efde776ad1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- user_id: integer (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- occupation: string (nullable = true)\n",
            " |-- zip_code: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "occupation.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cS0eyFnbOdmH"
      },
      "source": [
        "### Problem 1: Selecting Specific Columns\n",
        "Problem: Select the \"user_id,\" \"age,\" and \"occupation\" columns from the occupation DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "CWuoKeF6OdmH",
        "outputId": "6a8906c1-93ad-44cd-d27d-6e61614089d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+---+-------------+\n",
            "|user_id|age|   occupation|\n",
            "+-------+---+-------------+\n",
            "|      1| 24|   technician|\n",
            "|      2| 53|        other|\n",
            "|      3| 23|       writer|\n",
            "|      4| 24|   technician|\n",
            "|      5| 33|        other|\n",
            "|      6| 42|    executive|\n",
            "|      7| 57|administrator|\n",
            "|      8| 36|administrator|\n",
            "|      9| 29|      student|\n",
            "|     10| 53|       lawyer|\n",
            "|     11| 39|        other|\n",
            "|     12| 28|        other|\n",
            "|     13| 47|     educator|\n",
            "|     14| 45|    scientist|\n",
            "|     15| 49|     educator|\n",
            "|     16| 21|entertainment|\n",
            "|     17| 30|   programmer|\n",
            "|     18| 35|        other|\n",
            "|     19| 40|    librarian|\n",
            "|     20| 42|    homemaker|\n",
            "+-------+---+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "occupation.select(\"user_id\", \"age\", \"occupation\").show() #simply selects the columns and displays them"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jU96BgfUOdmI"
      },
      "source": [
        "### Problem 2: Filtering Rows based on Condition\n",
        "Problem: Find the users who are older than 30 years from the occupation DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+---+------+-------------+--------+\n",
            "|user_id|age|gender|   occupation|zip_code|\n",
            "+-------+---+------+-------------+--------+\n",
            "|      2| 53|     F|        other|   94043|\n",
            "|      5| 33|     F|        other|   15213|\n",
            "|      6| 42|     M|    executive|   98101|\n",
            "|      7| 57|     M|administrator|   91344|\n",
            "|      8| 36|     M|administrator|   05201|\n",
            "|     10| 53|     M|       lawyer|   90703|\n",
            "|     11| 39|     F|        other|   30329|\n",
            "|     13| 47|     M|     educator|   29206|\n",
            "|     14| 45|     M|    scientist|   55106|\n",
            "|     15| 49|     F|     educator|   97301|\n",
            "|     18| 35|     F|        other|   37212|\n",
            "|     19| 40|     M|    librarian|   02138|\n",
            "|     20| 42|     F|    homemaker|   95660|\n",
            "|     25| 39|     M|     engineer|   55107|\n",
            "|     26| 49|     M|     engineer|   21044|\n",
            "|     27| 40|     F|    librarian|   30030|\n",
            "|     28| 32|     M|       writer|   55369|\n",
            "|     29| 41|     M|   programmer|   94043|\n",
            "|     34| 38|     F|administrator|   42141|\n",
            "|     39| 41|     M|entertainment|   01040|\n",
            "+-------+---+------+-------------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "occupation.select(\"*\").filter(col(\"age\")>30).show() #selecting everything and filtering the age column to display age greater than 30"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UgD4jOROdmI"
      },
      "source": [
        "### Problem 3: Counting and Grouping\n",
        "Problem: Count the number of users in each occupation from the occupation DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+-----+\n",
            "|   occupation|count|\n",
            "+-------------+-----+\n",
            "|    librarian|   51|\n",
            "|      retired|   14|\n",
            "|       lawyer|   12|\n",
            "|         none|    9|\n",
            "|       writer|   45|\n",
            "|   programmer|   66|\n",
            "|    marketing|   26|\n",
            "|        other|  105|\n",
            "|    executive|   32|\n",
            "|    scientist|   31|\n",
            "|      student|  196|\n",
            "|     salesman|   12|\n",
            "|       artist|   28|\n",
            "|   technician|   27|\n",
            "|administrator|   79|\n",
            "|     engineer|   67|\n",
            "|   healthcare|   16|\n",
            "|     educator|   95|\n",
            "|entertainment|   18|\n",
            "|    homemaker|    7|\n",
            "+-------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "occupation.groupBy(\"occupation\").count().show() #groups by occupation and counts the total users in them"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_hay_fTOdmJ"
      },
      "source": [
        "### Problem 4: Adding a New Column\n",
        "Problem: Add a new column \"age_group\" to the occupation DataFrame based on the age of the users. Divide users into age groups: \"18-25\", \"26-35\", \"36-50\", and \"51+\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+---+------+-------------+--------+---------+\n",
            "|user_id|age|gender|   occupation|zip_code|age_group|\n",
            "+-------+---+------+-------------+--------+---------+\n",
            "|      1| 24|     M|   technician|   85711|    18-25|\n",
            "|      2| 53|     F|        other|   94043|      51+|\n",
            "|      3| 23|     M|       writer|   32067|    18-25|\n",
            "|      4| 24|     M|   technician|   43537|    18-25|\n",
            "|      5| 33|     F|        other|   15213|    26-35|\n",
            "|      6| 42|     M|    executive|   98101|    36-50|\n",
            "|      7| 57|     M|administrator|   91344|      51+|\n",
            "|      8| 36|     M|administrator|   05201|    36-50|\n",
            "|      9| 29|     M|      student|   01002|    26-35|\n",
            "|     10| 53|     M|       lawyer|   90703|      51+|\n",
            "|     11| 39|     F|        other|   30329|    36-50|\n",
            "|     12| 28|     F|        other|   06405|    26-35|\n",
            "|     13| 47|     M|     educator|   29206|    36-50|\n",
            "|     14| 45|     M|    scientist|   55106|    36-50|\n",
            "|     15| 49|     F|     educator|   97301|    36-50|\n",
            "|     16| 21|     M|entertainment|   10309|    18-25|\n",
            "|     17| 30|     M|   programmer|   06355|    26-35|\n",
            "|     18| 35|     F|        other|   37212|    26-35|\n",
            "|     19| 40|     M|    librarian|   02138|    36-50|\n",
            "|     20| 42|     F|    homemaker|   95660|    36-50|\n",
            "+-------+---+------+-------------+--------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import when, lit #importing when and lit, used to specify condition and input value for condition. lit inputs literal/strings\n",
        "#withColumn creates a new column\n",
        "occupation.withColumn(\"age_group\", \\ \n",
        "   when((occupation.age >= 18) & (occupation.age <= 25), lit(\"18-25\")) \\\n",
        "     .when((occupation.age >= 26) & (occupation.age <= 35), lit(\"26-35\")) \\\n",
        "      .when((occupation.age >= 36) & (occupation.age <= 50), lit(\"36-50\")) \\\n",
        "     .otherwise(lit(\"51+\")) \\\n",
        "  ).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAEhRUZ_OdmJ"
      },
      "source": [
        "### Problem 5: Creating DataFrames and Converting to Spark Types\n",
        "Problem: Given the provided code snippet, create a DataFrame df using the given data and schema. The schema includes columns for firstname, middlename, lastname, id, gender, and salary. After creating the DataFrame, print its schema and display its content without truncation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- firstname: string (nullable = true)\n",
            " |-- middlename: string (nullable = true)\n",
            " |-- lastname: string (nullable = true)\n",
            " |-- id: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- salary: long (nullable = true)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+----------+--------+-----+------+------+\n",
            "|firstname|middlename|lastname|id   |gender|salary|\n",
            "+---------+----------+--------+-----+------+------+\n",
            "|James    |          |Smith   |36636|M     |3000  |\n",
            "|Micheal  |Rose      |        |40288|M     |4000  |\n",
            "|Robert   |          |Williams|42114|M     |4000  |\n",
            "|Maria    |Anne      |Jones   |39192|F     |4000  |\n",
            "|Jen      |Mary      |Brown   |     |F     |-1    |\n",
            "+---------+----------+--------+-----+------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "Sample_Data = [(\"James\", \" \",\"Smith\", \"36636\", \"M\", 3000),\t\n",
        "          (\"Micheal\", \"Rose\", \" \", \"40288\", \"M\", 4000),\n",
        "          (\"Robert\", \" \",\"Williams\", \"42114\", \"M\", 4000),\n",
        "          (\"Maria\", \"Anne\",\"Jones\", \"39192\", \"F\", 4000),\n",
        "          (\"Jen\", \"Mary\", \"Brown\", \" \", \"F\", -1)\n",
        "  ]\t#inputting the data\n",
        "\n",
        "Sample_schema = [\"firstname\",\"middlename\",\"lastname\",\"id\",\"gender\",\"salary\"]\t\n",
        "dataframe = spark.createDataFrame(data = Sample_Data, schema = Sample_schema)\t\n",
        "\n",
        "dataframe.printSchema()\t\n",
        "dataframe.show(truncate=False)\t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d6HTbjkOdmJ"
      },
      "source": [
        "### Problem 6: Adding and Renaming Columns\n",
        "Problem: Add a new column \"gender\" to the existing DataFrame and rename the \"Age\" column to \"Years\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+-----+-------+-------------+--------+\n",
            "|user_id|Years| gender|   occupation|zip_code|\n",
            "+-------+-----+-------+-------------+--------+\n",
            "|      1|   24|Unknown|   technician|   85711|\n",
            "|      2|   53|Unknown|        other|   94043|\n",
            "|      3|   23|Unknown|       writer|   32067|\n",
            "|      4|   24|Unknown|   technician|   43537|\n",
            "|      5|   33|Unknown|        other|   15213|\n",
            "|      6|   42|Unknown|    executive|   98101|\n",
            "|      7|   57|Unknown|administrator|   91344|\n",
            "|      8|   36|Unknown|administrator|   05201|\n",
            "|      9|   29|Unknown|      student|   01002|\n",
            "|     10|   53|Unknown|       lawyer|   90703|\n",
            "|     11|   39|Unknown|        other|   30329|\n",
            "|     12|   28|Unknown|        other|   06405|\n",
            "|     13|   47|Unknown|     educator|   29206|\n",
            "|     14|   45|Unknown|    scientist|   55106|\n",
            "|     15|   49|Unknown|     educator|   97301|\n",
            "|     16|   21|Unknown|entertainment|   10309|\n",
            "|     17|   30|Unknown|   programmer|   06355|\n",
            "|     18|   35|Unknown|        other|   37212|\n",
            "|     19|   40|Unknown|    librarian|   02138|\n",
            "|     20|   42|Unknown|    homemaker|   95660|\n",
            "+-------+-----+-------+-------------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = occupation.withColumn(\"gender\",lit(\"Unknown\")) # adds a new column gender but since it already has it simply overwrites \n",
        "df2 = df.withColumnRenamed(\"age\",\"Years\") #renames the column age to years\n",
        "df2.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4fzgwd_OdmK"
      },
      "source": [
        "### Problem 7: Filtering Rows and Sorting\n",
        "Problem: Filter out users who are younger than 30 years and sort the DataFrame by age in descending order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+-----+-------+-------------+--------+\n",
            "|user_id|Years| gender|   occupation|zip_code|\n",
            "+-------+-----+-------+-------------+--------+\n",
            "|    481|   73|Unknown|      retired|   37771|\n",
            "|    767|   70|Unknown|     engineer|   00000|\n",
            "|    803|   70|Unknown|administrator|   78212|\n",
            "|    860|   70|Unknown|      retired|   48322|\n",
            "|    559|   69|Unknown|    executive|   10022|\n",
            "|    585|   69|Unknown|    librarian|   98501|\n",
            "|    349|   68|Unknown|      retired|   61455|\n",
            "|    573|   68|Unknown|      retired|   48911|\n",
            "|    211|   66|Unknown|     salesman|   32605|\n",
            "|    318|   65|Unknown|      retired|   06518|\n",
            "|    564|   65|Unknown|      retired|   94591|\n",
            "|    651|   65|Unknown|      retired|   02903|\n",
            "|    423|   64|Unknown|        other|   91606|\n",
            "|    845|   64|Unknown|       doctor|   97405|\n",
            "|    364|   63|Unknown|     engineer|   01810|\n",
            "|    777|   63|Unknown|   programmer|   01810|\n",
            "|    858|   63|Unknown|     educator|   09645|\n",
            "|    266|   62|Unknown|administrator|   78756|\n",
            "|    520|   62|Unknown|   healthcare|   12603|\n",
            "|    106|   61|Unknown|      retired|   55125|\n",
            "+-------+-----+-------+-------------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import desc\n",
        "df3 = df2.select(\"*\").filter(col(\"Years\")>30)\n",
        "df3.sort(desc(\"Years\")).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8aHnnCMOdmK"
      },
      "source": [
        "### Problem 8: Repartitioning and Collecting Rows\n",
        "Problem: Repartition the DataFrame into 2 partitions without shuffling the data, then collect and display all rows in the driver and print number of partitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Row(firstname='James', middlename=' ', lastname='Smith', id='36636', gender='M', salary=3000)\n",
            "Row(firstname='Micheal', middlename='Rose', lastname=' ', id='40288', gender='M', salary=4000)\n",
            "Row(firstname='Robert', middlename=' ', lastname='Williams', id='42114', gender='M', salary=4000)\n",
            "Row(firstname='Maria', middlename='Anne', lastname='Jones', id='39192', gender='F', salary=4000)\n",
            "Row(firstname='Jen', middlename='Mary', lastname='Brown', id=' ', gender='F', salary=-1)\n"
          ]
        }
      ],
      "source": [
        "partitioned_data = dataframe.coalesce(2) #partitions the dataframe without shuffling\n",
        "rows = partitioned_data.collect() #for smaller datasets, use this. It stores in array format\n",
        "for a in rows:\n",
        "    print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of Partitions = 2\n"
          ]
        }
      ],
      "source": [
        "number_of_partition = partitioned_data.rdd.getNumPartitions() #to get current number of partitions of a dataframe. It's called on the dataframe underlying RDD\n",
        "print(\"Number of Partitions =\",number_of_partition)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hzn_BGt_PuYH"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFKQzCADOdmK"
      },
      "source": [
        "### Additional questions:\n",
        "\n",
        "Use both spark SQL and Pyspark to obtain answer wherever relevant"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCJtYZAHS5hi"
      },
      "source": [
        "#### Filter out rows where the age is greater than 30 and create a new DataFrame. Then, add a new column named \"is_elderly\" with a value of \"True\" for these rows and \"False\" otherwise.Rename the \"gender\" column to \"sex\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+---+---+-------------+--------+----------+\n",
            "|user_id|age|sex|   occupation|zip_code|is_elderly|\n",
            "+-------+---+---+-------------+--------+----------+\n",
            "|      1| 24|  M|   technician|   85711|     false|\n",
            "|      2| 53|  F|        other|   94043|      true|\n",
            "|      3| 23|  M|       writer|   32067|     false|\n",
            "|      4| 24|  M|   technician|   43537|     false|\n",
            "|      5| 33|  F|        other|   15213|      true|\n",
            "|      6| 42|  M|    executive|   98101|      true|\n",
            "|      7| 57|  M|administrator|   91344|      true|\n",
            "|      8| 36|  M|administrator|   05201|      true|\n",
            "|      9| 29|  M|      student|   01002|     false|\n",
            "|     10| 53|  M|       lawyer|   90703|      true|\n",
            "|     11| 39|  F|        other|   30329|      true|\n",
            "|     12| 28|  F|        other|   06405|     false|\n",
            "|     13| 47|  M|     educator|   29206|      true|\n",
            "|     14| 45|  M|    scientist|   55106|      true|\n",
            "|     15| 49|  F|     educator|   97301|      true|\n",
            "|     16| 21|  M|entertainment|   10309|     false|\n",
            "|     17| 30|  M|   programmer|   06355|     false|\n",
            "|     18| 35|  F|        other|   37212|      true|\n",
            "|     19| 40|  M|    librarian|   02138|      true|\n",
            "|     20| 42|  F|    homemaker|   95660|      true|\n",
            "+-------+---+---+-------------+--------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Spark SQL\n",
        "occupation.createOrReplaceTempView(\"occu_temp\")\n",
        "\n",
        "result = spark.sql(\"\"\"select user_id, \n",
        "age, \n",
        "gender as sex,\n",
        "occupation, \n",
        "zip_code,\n",
        "case when age > 30 then True else False end as is_elderly\n",
        "from occu_temp\"\"\")\n",
        "result.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "p1Mr79WeQvzS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+---+---+-------------+--------+----------+\n",
            "|user_id|age|sex|   occupation|zip_code|is_elderly|\n",
            "+-------+---+---+-------------+--------+----------+\n",
            "|      1| 24|  M|   technician|   85711|     false|\n",
            "|      2| 53|  F|        other|   94043|      true|\n",
            "|      3| 23|  M|       writer|   32067|     false|\n",
            "|      4| 24|  M|   technician|   43537|     false|\n",
            "|      5| 33|  F|        other|   15213|      true|\n",
            "|      6| 42|  M|    executive|   98101|      true|\n",
            "|      7| 57|  M|administrator|   91344|      true|\n",
            "|      8| 36|  M|administrator|   05201|      true|\n",
            "|      9| 29|  M|      student|   01002|     false|\n",
            "|     10| 53|  M|       lawyer|   90703|      true|\n",
            "|     11| 39|  F|        other|   30329|      true|\n",
            "|     12| 28|  F|        other|   06405|     false|\n",
            "|     13| 47|  M|     educator|   29206|      true|\n",
            "|     14| 45|  M|    scientist|   55106|      true|\n",
            "|     15| 49|  F|     educator|   97301|      true|\n",
            "|     16| 21|  M|entertainment|   10309|     false|\n",
            "|     17| 30|  M|   programmer|   06355|     false|\n",
            "|     18| 35|  F|        other|   37212|      true|\n",
            "|     19| 40|  M|    librarian|   02138|      true|\n",
            "|     20| 42|  F|    homemaker|   95660|      true|\n",
            "+-------+---+---+-------------+--------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Pyspark\n",
        "#from pyspark.sql.functions import when, lit\n",
        "occupation1 = occupation.withColumnRenamed(\"gender\", \"sex\")\n",
        "occupation1.withColumn(\"is_elderly\", \\\n",
        "   when((occupation.age > 30), lit(\"true\")) \\\n",
        "     .otherwise(lit(\"false\")) \\\n",
        "  ).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoYi3_q7TCA9"
      },
      "source": [
        "#### Calculate the average age of male and female users separately. Present the result in a new DataFrame with columns \"gender\" and \"avg_age\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "Seri4fe5Q2Ti"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+------------------+\n",
            "|gender|           avg_age|\n",
            "+------+------------------+\n",
            "|     F| 33.81318681318681|\n",
            "|     M|34.149253731343286|\n",
            "+------+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Spark SQL\n",
        "occupation.createOrReplaceTempView(\"occu_temp1\")\n",
        "resul = spark.sql(\"\"\"select gender, \n",
        "avg(age) as avg_age\n",
        "from occu_temp1\n",
        "group by gender\"\"\")\n",
        "resul.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "433nZ-6lQv5F"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+------------------+\n",
            "|gender|           avg_age|\n",
            "+------+------------------+\n",
            "|     F| 33.81318681318681|\n",
            "|     M|34.149253731343286|\n",
            "+------+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Pyspark\n",
        "from pyspark.sql.functions import avg\n",
        "occuu1 = occupation.groupBy(\"gender\").agg(avg(\"age\").alias(\"avg_age\"))\n",
        "occuu1.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyMs561GTKtI"
      },
      "source": [
        "#### Add a new column named \"full_name\" to the dataset by concatenating the \"user_id\" and \"occupation\" columns. Then, rename the \"zip_code\" column to \"postal_code\" in the same DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "sZc6kifIQ2qa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+---+------+-------------+-----------+---------------+\n",
            "|user_id|age|gender|   occupation|postal_code|      full_name|\n",
            "+-------+---+------+-------------+-----------+---------------+\n",
            "|      1| 24|     M|   technician|      85711|    1technician|\n",
            "|      2| 53|     F|        other|      94043|         2other|\n",
            "|      3| 23|     M|       writer|      32067|        3writer|\n",
            "|      4| 24|     M|   technician|      43537|    4technician|\n",
            "|      5| 33|     F|        other|      15213|         5other|\n",
            "|      6| 42|     M|    executive|      98101|     6executive|\n",
            "|      7| 57|     M|administrator|      91344| 7administrator|\n",
            "|      8| 36|     M|administrator|      05201| 8administrator|\n",
            "|      9| 29|     M|      student|      01002|       9student|\n",
            "|     10| 53|     M|       lawyer|      90703|       10lawyer|\n",
            "|     11| 39|     F|        other|      30329|        11other|\n",
            "|     12| 28|     F|        other|      06405|        12other|\n",
            "|     13| 47|     M|     educator|      29206|     13educator|\n",
            "|     14| 45|     M|    scientist|      55106|    14scientist|\n",
            "|     15| 49|     F|     educator|      97301|     15educator|\n",
            "|     16| 21|     M|entertainment|      10309|16entertainment|\n",
            "|     17| 30|     M|   programmer|      06355|   17programmer|\n",
            "|     18| 35|     F|        other|      37212|        18other|\n",
            "|     19| 40|     M|    librarian|      02138|    19librarian|\n",
            "|     20| 42|     F|    homemaker|      95660|    20homemaker|\n",
            "+-------+---+------+-------------+-----------+---------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Spark SQL\n",
        "occupation.createOrReplaceTempView(\"occu_temp2\")\n",
        "\n",
        "result1 = spark.sql(\"\"\"select user_id, \n",
        "age, \n",
        "gender,\n",
        "occupation, \n",
        "zip_code as postal_code,\n",
        "concat(user_id, occupation) AS full_name\n",
        "from occu_temp2\"\"\")\n",
        "\n",
        "result1.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "hC_1VJbnQwFI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------+-------+---+------+-------------+--------+\n",
            "|      full_name|user_id|age|gender|   occupation|zip_code|\n",
            "+---------------+-------+---+------+-------------+--------+\n",
            "|    1technician|      1| 24|     M|   technician|   85711|\n",
            "|         2other|      2| 53|     F|        other|   94043|\n",
            "|        3writer|      3| 23|     M|       writer|   32067|\n",
            "|    4technician|      4| 24|     M|   technician|   43537|\n",
            "|         5other|      5| 33|     F|        other|   15213|\n",
            "|     6executive|      6| 42|     M|    executive|   98101|\n",
            "| 7administrator|      7| 57|     M|administrator|   91344|\n",
            "| 8administrator|      8| 36|     M|administrator|   05201|\n",
            "|       9student|      9| 29|     M|      student|   01002|\n",
            "|       10lawyer|     10| 53|     M|       lawyer|   90703|\n",
            "|        11other|     11| 39|     F|        other|   30329|\n",
            "|        12other|     12| 28|     F|        other|   06405|\n",
            "|     13educator|     13| 47|     M|     educator|   29206|\n",
            "|    14scientist|     14| 45|     M|    scientist|   55106|\n",
            "|     15educator|     15| 49|     F|     educator|   97301|\n",
            "|16entertainment|     16| 21|     M|entertainment|   10309|\n",
            "|   17programmer|     17| 30|     M|   programmer|   06355|\n",
            "|        18other|     18| 35|     F|        other|   37212|\n",
            "|    19librarian|     19| 40|     M|    librarian|   02138|\n",
            "|    20homemaker|     20| 42|     F|    homemaker|   95660|\n",
            "+---------------+-------+---+------+-------------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Pyspark\n",
        "#to be discussed\n",
        "from pyspark.sql.functions import concat\n",
        "dff2=occupation.select(concat(occupation.user_id, occupation.occupation).alias(\"full_name\"), \"user_id\", \"age\", \"gender\", \"occupation\", \"zip_code\")\n",
        "dff2.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CPDOqPZUTWd"
      },
      "source": [
        "#### Filter out rows where occupation is 'technician', select only the \"user_id\" and \"age\" columns, and then add a new column \"age_diff\" that calculates the difference between the user's age and the average age in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8-rf3eAUZ0q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HJ1PEFNUbg0"
      },
      "outputs": [],
      "source": [
        "# Pyspark\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTIR2tJuTRID"
      },
      "source": [
        "#### Divide the dataset into two DataFrames: one with male users and another with female users. Repartition both DataFrames to have 2 partitions each. Then, union these two DataFrames together and display the resulting DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JKAn2n0P6Ib"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfVdjYOcTn_g"
      },
      "source": [
        "#### Create and fill a new DataFrame named user_ratings with columns user_id and rating max 10 column. Both user_data and user_ratings share the user_id column. Combine these two DataFrames to create a new DataFrame that includes user information and their corresponding ratings. Make sure to keep only the users present in both DataFrames."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3Jw-vaEP4U4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "DQ",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
