{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0vyTaRGOdmB"
      },
      "source": [
        "## Basic Structured Operations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2KpLHzVOdmE"
      },
      "source": [
        "### Step 1: Initialize PySpark Session\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2Xue9qjMOdmE",
        "outputId": "5657c1b5-a544-4362-9219-3a4120a654b8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/09/04 16:54:34 WARN Utils: Your hostname, kushal-Latitude-E5440 resolves to a loopback address: 127.0.1.1; using 192.168.1.14 instead (on interface wlp2s0)\n",
            "23/09/04 16:54:34 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
            "23/09/04 16:54:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, expr\n",
        "\n",
        "# Create a Spark session\n",
        "spark = SparkSession.builder.appName(\"day2\").getOrCreate()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCeSCVDKOdmG"
      },
      "source": [
        "### Step 2: Load the Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QHmqfHtkOdmG"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "# Load the Occupation dataset into a Spark DataFrame\n",
        "data_path = \"occupation.csv\"  # Replace with the actual path\n",
        "occupation = spark.read.csv(data_path, header=True, inferSchema=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8629vMtbOdmG",
        "outputId": "80bc57c1-d3d3-49d8-c2d4-7efde776ad1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- user_id: integer (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- occupation: string (nullable = true)\n",
            " |-- zip_code: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "occupation.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cS0eyFnbOdmH"
      },
      "source": [
        "### Problem 1: Selecting Specific Columns\n",
        "Problem: Select the \"user_id,\" \"age,\" and \"occupation\" columns from the occupation DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CWuoKeF6OdmH",
        "outputId": "6a8906c1-93ad-44cd-d27d-6e61614089d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+---+-------------+\n",
            "|user_id|age|   occupation|\n",
            "+-------+---+-------------+\n",
            "|      1| 24|   technician|\n",
            "|      2| 53|        other|\n",
            "|      3| 23|       writer|\n",
            "|      4| 24|   technician|\n",
            "|      5| 33|        other|\n",
            "|      6| 42|    executive|\n",
            "|      7| 57|administrator|\n",
            "|      8| 36|administrator|\n",
            "|      9| 29|      student|\n",
            "|     10| 53|       lawyer|\n",
            "|     11| 39|        other|\n",
            "|     12| 28|        other|\n",
            "|     13| 47|     educator|\n",
            "|     14| 45|    scientist|\n",
            "|     15| 49|     educator|\n",
            "|     16| 21|entertainment|\n",
            "|     17| 30|   programmer|\n",
            "|     18| 35|        other|\n",
            "|     19| 40|    librarian|\n",
            "|     20| 42|    homemaker|\n",
            "+-------+---+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "occupation.select(\"user_id\", \"age\", \"occupation\").show() #simply selects the columns and displays them"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jU96BgfUOdmI"
      },
      "source": [
        "### Problem 2: Filtering Rows based on Condition\n",
        "Problem: Find the users who are older than 30 years from the occupation DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+---+------+-------------+--------+\n",
            "|user_id|age|gender|   occupation|zip_code|\n",
            "+-------+---+------+-------------+--------+\n",
            "|      2| 53|     F|        other|   94043|\n",
            "|      5| 33|     F|        other|   15213|\n",
            "|      6| 42|     M|    executive|   98101|\n",
            "|      7| 57|     M|administrator|   91344|\n",
            "|      8| 36|     M|administrator|   05201|\n",
            "|     10| 53|     M|       lawyer|   90703|\n",
            "|     11| 39|     F|        other|   30329|\n",
            "|     13| 47|     M|     educator|   29206|\n",
            "|     14| 45|     M|    scientist|   55106|\n",
            "|     15| 49|     F|     educator|   97301|\n",
            "|     18| 35|     F|        other|   37212|\n",
            "|     19| 40|     M|    librarian|   02138|\n",
            "|     20| 42|     F|    homemaker|   95660|\n",
            "|     25| 39|     M|     engineer|   55107|\n",
            "|     26| 49|     M|     engineer|   21044|\n",
            "|     27| 40|     F|    librarian|   30030|\n",
            "|     28| 32|     M|       writer|   55369|\n",
            "|     29| 41|     M|   programmer|   94043|\n",
            "|     34| 38|     F|administrator|   42141|\n",
            "|     39| 41|     M|entertainment|   01040|\n",
            "+-------+---+------+-------------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "occupation.select(\"*\").filter(col(\"age\")>30).show() #selecting everything and filtering the age column to display age greater than 30"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UgD4jOROdmI"
      },
      "source": [
        "### Problem 3: Counting and Grouping\n",
        "Problem: Count the number of users in each occupation from the occupation DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 4:>                                                          (0 + 1) / 1]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+-----+\n",
            "|   occupation|count|\n",
            "+-------------+-----+\n",
            "|    librarian|   51|\n",
            "|      retired|   14|\n",
            "|       lawyer|   12|\n",
            "|         none|    9|\n",
            "|       writer|   45|\n",
            "|   programmer|   66|\n",
            "|    marketing|   26|\n",
            "|        other|  105|\n",
            "|    executive|   32|\n",
            "|    scientist|   31|\n",
            "|      student|  196|\n",
            "|     salesman|   12|\n",
            "|       artist|   28|\n",
            "|   technician|   27|\n",
            "|administrator|   79|\n",
            "|     engineer|   67|\n",
            "|   healthcare|   16|\n",
            "|     educator|   95|\n",
            "|entertainment|   18|\n",
            "|    homemaker|    7|\n",
            "+-------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "occupation.groupBy(\"occupation\").count().show() #groups by occupation and counts the total users in them"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_hay_fTOdmJ"
      },
      "source": [
        "### Problem 4: Adding a New Column\n",
        "Problem: Add a new column \"age_group\" to the occupation DataFrame based on the age of the users. Divide users into age groups: \"18-25\", \"26-35\", \"36-50\", and \"51+\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+---+------+-------------+--------+---------+\n",
            "|user_id|age|gender|   occupation|zip_code|age_group|\n",
            "+-------+---+------+-------------+--------+---------+\n",
            "|      1| 24|     M|   technician|   85711|    18-25|\n",
            "|      2| 53|     F|        other|   94043|      51+|\n",
            "|      3| 23|     M|       writer|   32067|    18-25|\n",
            "|      4| 24|     M|   technician|   43537|    18-25|\n",
            "|      5| 33|     F|        other|   15213|    26-35|\n",
            "|      6| 42|     M|    executive|   98101|    36-50|\n",
            "|      7| 57|     M|administrator|   91344|      51+|\n",
            "|      8| 36|     M|administrator|   05201|    36-50|\n",
            "|      9| 29|     M|      student|   01002|    26-35|\n",
            "|     10| 53|     M|       lawyer|   90703|      51+|\n",
            "|     11| 39|     F|        other|   30329|    36-50|\n",
            "|     12| 28|     F|        other|   06405|    26-35|\n",
            "|     13| 47|     M|     educator|   29206|    36-50|\n",
            "|     14| 45|     M|    scientist|   55106|    36-50|\n",
            "|     15| 49|     F|     educator|   97301|    36-50|\n",
            "|     16| 21|     M|entertainment|   10309|    18-25|\n",
            "|     17| 30|     M|   programmer|   06355|    26-35|\n",
            "|     18| 35|     F|        other|   37212|    26-35|\n",
            "|     19| 40|     M|    librarian|   02138|    36-50|\n",
            "|     20| 42|     F|    homemaker|   95660|    36-50|\n",
            "+-------+---+------+-------------+--------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import when, lit #importing when and lit, used to specify condition and input value for condition. lit inputs literal/strings\n",
        "#withColumn creates a new column\n",
        "occupation.withColumn(\"age_group\", \n",
        "   when((occupation.age >= 18) & (occupation.age <= 25), lit(\"18-25\")) \\\n",
        "     .when((occupation.age >= 26) & (occupation.age <= 35), lit(\"26-35\")) \\\n",
        "      .when((occupation.age >= 36) & (occupation.age <= 50), lit(\"36-50\")) \\\n",
        "     .otherwise(lit(\"51+\")) \\\n",
        "  ).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAEhRUZ_OdmJ"
      },
      "source": [
        "### Problem 5: Creating DataFrames and Converting to Spark Types\n",
        "Problem: Given the provided code snippet, create a DataFrame df using the given data and schema. The schema includes columns for firstname, middlename, lastname, id, gender, and salary. After creating the DataFrame, print its schema and display its content without truncation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- firstname: string (nullable = true)\n",
            " |-- middlename: string (nullable = true)\n",
            " |-- lastname: string (nullable = true)\n",
            " |-- id: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- salary: long (nullable = true)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+----------+--------+-----+------+------+\n",
            "|firstname|middlename|lastname|id   |gender|salary|\n",
            "+---------+----------+--------+-----+------+------+\n",
            "|James    |          |Smith   |36636|M     |3000  |\n",
            "|Micheal  |Rose      |        |40288|M     |4000  |\n",
            "|Robert   |          |Williams|42114|M     |4000  |\n",
            "|Maria    |Anne      |Jones   |39192|F     |4000  |\n",
            "|Jen      |Mary      |Brown   |     |F     |-1    |\n",
            "+---------+----------+--------+-----+------+------+\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "Sample_Data = [(\"James\", \" \",\"Smith\", \"36636\", \"M\", 3000),\t\n",
        "          (\"Micheal\", \"Rose\", \" \", \"40288\", \"M\", 4000),\n",
        "          (\"Robert\", \" \",\"Williams\", \"42114\", \"M\", 4000),\n",
        "          (\"Maria\", \"Anne\",\"Jones\", \"39192\", \"F\", 4000),\n",
        "          (\"Jen\", \"Mary\", \"Brown\", \" \", \"F\", -1)\n",
        "  ]\t#inputting the data\n",
        "\n",
        "Sample_schema = [\"firstname\",\"middlename\",\"lastname\",\"id\",\"gender\",\"salary\"]\t\n",
        "dataframe = spark.createDataFrame(data = Sample_Data, schema = Sample_schema)\t\n",
        "\n",
        "dataframe.printSchema()\t\n",
        "dataframe.show(truncate=False)\t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d6HTbjkOdmJ"
      },
      "source": [
        "### Problem 6: Adding and Renaming Columns\n",
        "Problem: Add a new column \"gender\" to the existing DataFrame and rename the \"Age\" column to \"Years\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+-----+-------+-------------+--------+\n",
            "|user_id|Years| gender|   occupation|zip_code|\n",
            "+-------+-----+-------+-------------+--------+\n",
            "|      1|   24|Unknown|   technician|   85711|\n",
            "|      2|   53|Unknown|        other|   94043|\n",
            "|      3|   23|Unknown|       writer|   32067|\n",
            "|      4|   24|Unknown|   technician|   43537|\n",
            "|      5|   33|Unknown|        other|   15213|\n",
            "|      6|   42|Unknown|    executive|   98101|\n",
            "|      7|   57|Unknown|administrator|   91344|\n",
            "|      8|   36|Unknown|administrator|   05201|\n",
            "|      9|   29|Unknown|      student|   01002|\n",
            "|     10|   53|Unknown|       lawyer|   90703|\n",
            "|     11|   39|Unknown|        other|   30329|\n",
            "|     12|   28|Unknown|        other|   06405|\n",
            "|     13|   47|Unknown|     educator|   29206|\n",
            "|     14|   45|Unknown|    scientist|   55106|\n",
            "|     15|   49|Unknown|     educator|   97301|\n",
            "|     16|   21|Unknown|entertainment|   10309|\n",
            "|     17|   30|Unknown|   programmer|   06355|\n",
            "|     18|   35|Unknown|        other|   37212|\n",
            "|     19|   40|Unknown|    librarian|   02138|\n",
            "|     20|   42|Unknown|    homemaker|   95660|\n",
            "+-------+-----+-------+-------------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = occupation.withColumn(\"gender\",lit(\"Unknown\")) # adds a new column gender but since it already has it simply overwrites \n",
        "df2 = df.withColumnRenamed(\"age\",\"Years\") #renames the column age to years\n",
        "df2.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4fzgwd_OdmK"
      },
      "source": [
        "### Problem 7: Filtering Rows and Sorting\n",
        "Problem: Filter out users who are younger than 30 years and sort the DataFrame by age in descending order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+-----+-------+-------------+--------+\n",
            "|user_id|Years| gender|   occupation|zip_code|\n",
            "+-------+-----+-------+-------------+--------+\n",
            "|    481|   73|Unknown|      retired|   37771|\n",
            "|    767|   70|Unknown|     engineer|   00000|\n",
            "|    803|   70|Unknown|administrator|   78212|\n",
            "|    860|   70|Unknown|      retired|   48322|\n",
            "|    559|   69|Unknown|    executive|   10022|\n",
            "|    585|   69|Unknown|    librarian|   98501|\n",
            "|    349|   68|Unknown|      retired|   61455|\n",
            "|    573|   68|Unknown|      retired|   48911|\n",
            "|    211|   66|Unknown|     salesman|   32605|\n",
            "|    318|   65|Unknown|      retired|   06518|\n",
            "|    564|   65|Unknown|      retired|   94591|\n",
            "|    651|   65|Unknown|      retired|   02903|\n",
            "|    423|   64|Unknown|        other|   91606|\n",
            "|    845|   64|Unknown|       doctor|   97405|\n",
            "|    364|   63|Unknown|     engineer|   01810|\n",
            "|    777|   63|Unknown|   programmer|   01810|\n",
            "|    858|   63|Unknown|     educator|   09645|\n",
            "|    266|   62|Unknown|administrator|   78756|\n",
            "|    520|   62|Unknown|   healthcare|   12603|\n",
            "|    106|   61|Unknown|      retired|   55125|\n",
            "+-------+-----+-------+-------------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import desc\n",
        "df3 = df2.select(\"*\").filter(col(\"Years\")>30)\n",
        "df3.sort(desc(\"Years\")).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8aHnnCMOdmK"
      },
      "source": [
        "### Problem 8: Repartitioning and Collecting Rows\n",
        "Problem: Repartition the DataFrame into 2 partitions without shuffling the data, then collect and display all rows in the driver and print number of partitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 12:>                                                         (0 + 2) / 2]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Row(firstname='James', middlename=' ', lastname='Smith', id='36636', gender='M', salary=3000)\n",
            "Row(firstname='Micheal', middlename='Rose', lastname=' ', id='40288', gender='M', salary=4000)\n",
            "Row(firstname='Robert', middlename=' ', lastname='Williams', id='42114', gender='M', salary=4000)\n",
            "Row(firstname='Maria', middlename='Anne', lastname='Jones', id='39192', gender='F', salary=4000)\n",
            "Row(firstname='Jen', middlename='Mary', lastname='Brown', id=' ', gender='F', salary=-1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "partitioned_data = dataframe.coalesce(2) #partitions the dataframe without shuffling\n",
        "rows = partitioned_data.collect() #for smaller datasets, use this. It stores in array format\n",
        "for a in rows:\n",
        "    print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of Partitions = 2\n"
          ]
        }
      ],
      "source": [
        "number_of_partition = partitioned_data.rdd.getNumPartitions() #to get current number of partitions of a dataframe. It's called on the dataframe underlying RDD\n",
        "print(\"Number of Partitions =\",number_of_partition)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hzn_BGt_PuYH"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFKQzCADOdmK"
      },
      "source": [
        "### Additional questions:\n",
        "\n",
        "Use both spark SQL and Pyspark to obtain answer wherever relevant"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCJtYZAHS5hi"
      },
      "source": [
        "#### Filter out rows where the age is greater than 30 and create a new DataFrame. Then, add a new column named \"is_elderly\" with a value of \"True\" for these rows and \"False\" otherwise.Rename the \"gender\" column to \"sex\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+---+---+-------------+--------+----------+\n",
            "|user_id|age|sex|   occupation|zip_code|is_elderly|\n",
            "+-------+---+---+-------------+--------+----------+\n",
            "|      1| 24|  M|   technician|   85711|     false|\n",
            "|      2| 53|  F|        other|   94043|      true|\n",
            "|      3| 23|  M|       writer|   32067|     false|\n",
            "|      4| 24|  M|   technician|   43537|     false|\n",
            "|      5| 33|  F|        other|   15213|      true|\n",
            "|      6| 42|  M|    executive|   98101|      true|\n",
            "|      7| 57|  M|administrator|   91344|      true|\n",
            "|      8| 36|  M|administrator|   05201|      true|\n",
            "|      9| 29|  M|      student|   01002|     false|\n",
            "|     10| 53|  M|       lawyer|   90703|      true|\n",
            "|     11| 39|  F|        other|   30329|      true|\n",
            "|     12| 28|  F|        other|   06405|     false|\n",
            "|     13| 47|  M|     educator|   29206|      true|\n",
            "|     14| 45|  M|    scientist|   55106|      true|\n",
            "|     15| 49|  F|     educator|   97301|      true|\n",
            "|     16| 21|  M|entertainment|   10309|     false|\n",
            "|     17| 30|  M|   programmer|   06355|     false|\n",
            "|     18| 35|  F|        other|   37212|      true|\n",
            "|     19| 40|  M|    librarian|   02138|      true|\n",
            "|     20| 42|  F|    homemaker|   95660|      true|\n",
            "+-------+---+---+-------------+--------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Spark SQL\n",
        "occupation.createOrReplaceTempView(\"occu_temp\")\n",
        "\n",
        "result = spark.sql(\"\"\"select user_id, \n",
        "age, \n",
        "gender as sex,\n",
        "occupation, \n",
        "zip_code,\n",
        "case when age > 30 then True else False end as is_elderly\n",
        "from occu_temp\"\"\")\n",
        "result.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "p1Mr79WeQvzS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+---+---+-------------+--------+----------+\n",
            "|user_id|age|sex|   occupation|zip_code|is_elderly|\n",
            "+-------+---+---+-------------+--------+----------+\n",
            "|      1| 24|  M|   technician|   85711|     false|\n",
            "|      2| 53|  F|        other|   94043|      true|\n",
            "|      3| 23|  M|       writer|   32067|     false|\n",
            "|      4| 24|  M|   technician|   43537|     false|\n",
            "|      5| 33|  F|        other|   15213|      true|\n",
            "|      6| 42|  M|    executive|   98101|      true|\n",
            "|      7| 57|  M|administrator|   91344|      true|\n",
            "|      8| 36|  M|administrator|   05201|      true|\n",
            "|      9| 29|  M|      student|   01002|     false|\n",
            "|     10| 53|  M|       lawyer|   90703|      true|\n",
            "|     11| 39|  F|        other|   30329|      true|\n",
            "|     12| 28|  F|        other|   06405|     false|\n",
            "|     13| 47|  M|     educator|   29206|      true|\n",
            "|     14| 45|  M|    scientist|   55106|      true|\n",
            "|     15| 49|  F|     educator|   97301|      true|\n",
            "|     16| 21|  M|entertainment|   10309|     false|\n",
            "|     17| 30|  M|   programmer|   06355|     false|\n",
            "|     18| 35|  F|        other|   37212|      true|\n",
            "|     19| 40|  M|    librarian|   02138|      true|\n",
            "|     20| 42|  F|    homemaker|   95660|      true|\n",
            "+-------+---+---+-------------+--------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Pyspark\n",
        "#from pyspark.sql.functions import when, lit\n",
        "occupation1 = occupation.withColumnRenamed(\"gender\", \"sex\")\n",
        "occupation1.withColumn(\"is_elderly\", \\\n",
        "   when((occupation.age > 30), lit(\"true\")) \\\n",
        "     .otherwise(lit(\"false\")) \\\n",
        "  ).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoYi3_q7TCA9"
      },
      "source": [
        "#### Calculate the average age of male and female users separately. Present the result in a new DataFrame with columns \"gender\" and \"avg_age\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Seri4fe5Q2Ti"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+------------------+\n",
            "|gender|           avg_age|\n",
            "+------+------------------+\n",
            "|     F| 33.81318681318681|\n",
            "|     M|34.149253731343286|\n",
            "+------+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Spark SQL\n",
        "occupation.createOrReplaceTempView(\"occu_temp1\")\n",
        "resul = spark.sql(\"\"\"select gender, \n",
        "avg(age) as avg_age\n",
        "from occu_temp1\n",
        "group by gender\"\"\")\n",
        "resul.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "433nZ-6lQv5F"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+------------------+\n",
            "|gender|           avg_age|\n",
            "+------+------------------+\n",
            "|     F| 33.81318681318681|\n",
            "|     M|34.149253731343286|\n",
            "+------+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Pyspark\n",
        "from pyspark.sql.functions import avg\n",
        "occuu1 = occupation.groupBy(\"gender\").agg(avg(\"age\").alias(\"avg_age\"))\n",
        "occuu1.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyMs561GTKtI"
      },
      "source": [
        "#### Add a new column named \"full_name\" to the dataset by concatenating the \"user_id\" and \"occupation\" columns. Then, rename the \"zip_code\" column to \"postal_code\" in the same DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "sZc6kifIQ2qa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+---+------+-------------+-----------+---------------+\n",
            "|user_id|age|gender|   occupation|postal_code|      full_name|\n",
            "+-------+---+------+-------------+-----------+---------------+\n",
            "|      1| 24|     M|   technician|      85711|    1technician|\n",
            "|      2| 53|     F|        other|      94043|         2other|\n",
            "|      3| 23|     M|       writer|      32067|        3writer|\n",
            "|      4| 24|     M|   technician|      43537|    4technician|\n",
            "|      5| 33|     F|        other|      15213|         5other|\n",
            "|      6| 42|     M|    executive|      98101|     6executive|\n",
            "|      7| 57|     M|administrator|      91344| 7administrator|\n",
            "|      8| 36|     M|administrator|      05201| 8administrator|\n",
            "|      9| 29|     M|      student|      01002|       9student|\n",
            "|     10| 53|     M|       lawyer|      90703|       10lawyer|\n",
            "|     11| 39|     F|        other|      30329|        11other|\n",
            "|     12| 28|     F|        other|      06405|        12other|\n",
            "|     13| 47|     M|     educator|      29206|     13educator|\n",
            "|     14| 45|     M|    scientist|      55106|    14scientist|\n",
            "|     15| 49|     F|     educator|      97301|     15educator|\n",
            "|     16| 21|     M|entertainment|      10309|16entertainment|\n",
            "|     17| 30|     M|   programmer|      06355|   17programmer|\n",
            "|     18| 35|     F|        other|      37212|        18other|\n",
            "|     19| 40|     M|    librarian|      02138|    19librarian|\n",
            "|     20| 42|     F|    homemaker|      95660|    20homemaker|\n",
            "+-------+---+------+-------------+-----------+---------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Spark SQL\n",
        "occupation.createOrReplaceTempView(\"occu_temp2\")\n",
        "\n",
        "result1 = spark.sql(\"\"\"select user_id, \n",
        "age, \n",
        "gender,\n",
        "occupation, \n",
        "zip_code as postal_code,\n",
        "concat(user_id, occupation) AS full_name\n",
        "from occu_temp2\"\"\")\n",
        "\n",
        "result1.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "hC_1VJbnQwFI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------+-------+---+------+-------------+--------+\n",
            "|      full_name|user_id|age|gender|   occupation|zip_code|\n",
            "+---------------+-------+---+------+-------------+--------+\n",
            "|    1technician|      1| 24|     M|   technician|   85711|\n",
            "|         2other|      2| 53|     F|        other|   94043|\n",
            "|        3writer|      3| 23|     M|       writer|   32067|\n",
            "|    4technician|      4| 24|     M|   technician|   43537|\n",
            "|         5other|      5| 33|     F|        other|   15213|\n",
            "|     6executive|      6| 42|     M|    executive|   98101|\n",
            "| 7administrator|      7| 57|     M|administrator|   91344|\n",
            "| 8administrator|      8| 36|     M|administrator|   05201|\n",
            "|       9student|      9| 29|     M|      student|   01002|\n",
            "|       10lawyer|     10| 53|     M|       lawyer|   90703|\n",
            "|        11other|     11| 39|     F|        other|   30329|\n",
            "|        12other|     12| 28|     F|        other|   06405|\n",
            "|     13educator|     13| 47|     M|     educator|   29206|\n",
            "|    14scientist|     14| 45|     M|    scientist|   55106|\n",
            "|     15educator|     15| 49|     F|     educator|   97301|\n",
            "|16entertainment|     16| 21|     M|entertainment|   10309|\n",
            "|   17programmer|     17| 30|     M|   programmer|   06355|\n",
            "|        18other|     18| 35|     F|        other|   37212|\n",
            "|    19librarian|     19| 40|     M|    librarian|   02138|\n",
            "|    20homemaker|     20| 42|     F|    homemaker|   95660|\n",
            "+---------------+-------+---+------+-------------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Pyspark\n",
        "#to be discussed\n",
        "from pyspark.sql.functions import concat\n",
        "dff2=occupation.select(concat(occupation.user_id, occupation.occupation).alias(\"full_name\"), \"user_id\", \"age\", \"gender\", \"occupation\", \"zip_code\")\n",
        "dff2.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CPDOqPZUTWd"
      },
      "source": [
        "#### Filter out rows where occupation is 'technician', select only the \"user_id\" and \"age\" columns, and then add a new column \"age_diff\" that calculates the difference between the user's age and the average age in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "K8-rf3eAUZ0q"
      },
      "outputs": [],
      "source": [
        "occupation.createOrReplaceTempView(\"occu_tmp3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+---+------------------+\n",
            "|user_id|age|          age_diff|\n",
            "+-------+---+------------------+\n",
            "|      1| 24|-10.05196182396607|\n",
            "|      4| 24|-10.05196182396607|\n",
            "|     44| 26| -8.05196182396607|\n",
            "|     77| 30| -4.05196182396607|\n",
            "|    143| 42|  7.94803817603393|\n",
            "|    197| 55| 20.94803817603393|\n",
            "|    244| 28| -6.05196182396607|\n",
            "|    294| 34| -0.05196182396607|\n",
            "|    311| 32| -2.05196182396607|\n",
            "|    325| 48| 13.94803817603393|\n",
            "|    441| 50| 15.94803817603393|\n",
            "|    456| 24|-10.05196182396607|\n",
            "|    458| 47| 12.94803817603393|\n",
            "|    488| 48| 13.94803817603393|\n",
            "|    545| 27| -7.05196182396607|\n",
            "|    670| 30| -4.05196182396607|\n",
            "|    715| 21|-13.05196182396607|\n",
            "|    717| 24|-10.05196182396607|\n",
            "|    718| 42|  7.94803817603393|\n",
            "|    738| 35|  0.94803817603393|\n",
            "+-------+---+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "average_age = spark.sql(\"SELECT AVG(age) AS avg_age FROM occu_tmp3\").collect()[0][\"avg_age\"]\n",
        "spark.sql(\"SELECT user_id, age, age - {} AS age_diff FROM occu_tmp3 WHERE occupation = 'technician'\"\n",
        "          .format(average_age)) \\\n",
        "    .show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "-HJ1PEFNUbg0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+---+-------------------+\n",
            "|user_id|age|           age_diff|\n",
            "+-------+---+-------------------+\n",
            "|      1| 24|-10.051961823966067|\n",
            "|      4| 24|-10.051961823966067|\n",
            "|     44| 26| -8.051961823966067|\n",
            "|     77| 30| -4.051961823966067|\n",
            "|    143| 42|  7.948038176033933|\n",
            "|    197| 55| 20.948038176033933|\n",
            "|    244| 28| -6.051961823966067|\n",
            "|    294| 34|-0.0519618239660673|\n",
            "|    311| 32|-2.0519618239660673|\n",
            "|    325| 48| 13.948038176033933|\n",
            "|    441| 50| 15.948038176033933|\n",
            "|    456| 24|-10.051961823966067|\n",
            "|    458| 47| 12.948038176033933|\n",
            "|    488| 48| 13.948038176033933|\n",
            "|    545| 27| -7.051961823966067|\n",
            "|    670| 30| -4.051961823966067|\n",
            "|    715| 21|-13.051961823966067|\n",
            "|    717| 24|-10.051961823966067|\n",
            "|    718| 42|  7.948038176033933|\n",
            "|    738| 35| 0.9480381760339327|\n",
            "+-------+---+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Pyspark\n",
        "average_age = occupation.select(avg(\"age\")).collect()[0][0]\n",
        "age_dif_df = occupation.filter(col(\"occupation\") == \"technician\") \\\n",
        "                       .select(\"user_id\", \"age\") \\\n",
        "                       .withColumn(\"age_diff\", col(\"age\") - average_age)\n",
        "\n",
        "age_dif_df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTIR2tJuTRID"
      },
      "source": [
        "#### Divide the dataset into two DataFrames: one with male users and another with female users. Repartition both DataFrames to have 2 partitions each. Then, union these two DataFrames together and display the resulting DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "4JKAn2n0P6Ib"
      },
      "outputs": [],
      "source": [
        "occupation.createOrReplaceTempView(\"occu_tmp4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+---+------+----------+--------+\n",
            "|user_id|age|gender|occupation|zip_code|\n",
            "+-------+---+------+----------+--------+\n",
            "|896    |28 |M     |writer    |91505   |\n",
            "|156    |25 |M     |educator  |08360   |\n",
            "|568    |39 |M     |educator  |01915   |\n",
            "|624    |19 |M     |student   |30067   |\n",
            "|832    |24 |M     |technician|77042   |\n",
            "|684    |28 |M     |student   |55414   |\n",
            "|905    |27 |M     |other     |30350   |\n",
            "|148    |33 |M     |engineer  |97006   |\n",
            "|313    |41 |M     |marketing |60035   |\n",
            "|478    |29 |M     |other     |10019   |\n",
            "|332    |20 |M     |student   |40504   |\n",
            "|492    |57 |M     |educator  |94618   |\n",
            "|833    |34 |M     |writer    |90019   |\n",
            "|470    |24 |M     |programmer|10021   |\n",
            "|21     |26 |M     |writer    |30068   |\n",
            "|265    |26 |M     |executive |84601   |\n",
            "|33     |23 |M     |student   |27510   |\n",
            "|133    |53 |M     |engineer  |78602   |\n",
            "|682    |23 |M     |programmer|55128   |\n",
            "|650    |42 |M     |engineer  |83814   |\n",
            "+-------+---+------+----------+--------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Number of partitions here: 2\n"
          ]
        }
      ],
      "source": [
        "male_df = spark.sql(\"\"\"\n",
        "                    select * from occu_tmp4\n",
        "                    where gender = \"M\"\n",
        "                     \"\"\").repartition(2)\n",
        "                \n",
        "male_df.show(truncate=False)\n",
        "num_partitions = male_df.rdd.getNumPartitions()\n",
        "print(\"Number of partitions here:\",num_partitions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+---+------+-------------+--------+\n",
            "|user_id|age|gender|occupation   |zip_code|\n",
            "+-------+---+------+-------------+--------+\n",
            "|505    |27 |F     |other        |20657   |\n",
            "|241    |26 |F     |student      |20001   |\n",
            "|629    |46 |F     |other        |44224   |\n",
            "|482    |18 |F     |student      |40256   |\n",
            "|304    |22 |F     |student      |71701   |\n",
            "|147    |40 |F     |librarian    |02143   |\n",
            "|354    |29 |F     |librarian    |48197   |\n",
            "|588    |18 |F     |student      |93063   |\n",
            "|175    |26 |F     |scientist    |21911   |\n",
            "|490    |29 |F     |artist       |V5A2B   |\n",
            "|457    |33 |F     |salesman     |30011   |\n",
            "|165    |20 |F     |other        |53715   |\n",
            "|342    |25 |F     |other        |98006   |\n",
            "|401    |46 |F     |healthcare   |84107   |\n",
            "|681    |44 |F     |marketing    |97208   |\n",
            "|238    |42 |F     |administrator|44124   |\n",
            "|52     |18 |F     |student      |55105   |\n",
            "|556    |35 |F     |educator     |30606   |\n",
            "|485    |44 |F     |educator     |95821   |\n",
            "|126    |28 |F     |lawyer       |20015   |\n",
            "+-------+---+------+-------------+--------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Number of partitions here: 2\n"
          ]
        }
      ],
      "source": [
        "\n",
        "female_df = spark.sql(\"\"\"\n",
        "                    select * from occu_tmp4\n",
        "                    where gender = \"F\"\n",
        "                     \"\"\").repartition(2)\n",
        "                \n",
        "female_df.show(truncate=False)\n",
        "num_partitions = female_df.rdd.getNumPartitions()\n",
        "print(\"Number of partitions here:\", num_partitions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+---+------+----------+--------+\n",
            "|user_id|age|gender|occupation|zip_code|\n",
            "+-------+---+------+----------+--------+\n",
            "|896    |28 |M     |writer    |91505   |\n",
            "|156    |25 |M     |educator  |08360   |\n",
            "|568    |39 |M     |educator  |01915   |\n",
            "|624    |19 |M     |student   |30067   |\n",
            "|832    |24 |M     |technician|77042   |\n",
            "|684    |28 |M     |student   |55414   |\n",
            "|905    |27 |M     |other     |30350   |\n",
            "|148    |33 |M     |engineer  |97006   |\n",
            "|313    |41 |M     |marketing |60035   |\n",
            "|478    |29 |M     |other     |10019   |\n",
            "|332    |20 |M     |student   |40504   |\n",
            "|492    |57 |M     |educator  |94618   |\n",
            "|833    |34 |M     |writer    |90019   |\n",
            "|470    |24 |M     |programmer|10021   |\n",
            "|21     |26 |M     |writer    |30068   |\n",
            "|265    |26 |M     |executive |84601   |\n",
            "|33     |23 |M     |student   |27510   |\n",
            "|133    |53 |M     |engineer  |78602   |\n",
            "|682    |23 |M     |programmer|55128   |\n",
            "|650    |42 |M     |engineer  |83814   |\n",
            "+-------+---+------+----------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "resulting_df = male_df.union(female_df)\n",
        "resulting_df.show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfVdjYOcTn_g"
      },
      "source": [
        "#### Create and fill a new DataFrame named user_ratings with columns user_id and rating max 10 column. Both user_data and user_ratings share the user_id column. Combine these two DataFrames to create a new DataFrame that includes user information and their corresponding ratings. Make sure to keep only the users present in both DataFrames."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "a3Jw-vaEP4U4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+--------+\n",
            "|user_id|    name|\n",
            "+-------+--------+\n",
            "|      1| Darshan|\n",
            "|      2|  Mukund|\n",
            "|      3|     Raj|\n",
            "|      4|Sadiksha|\n",
            "|      5|  Kushal|\n",
            "|      6|Himanshu|\n",
            "|      7|  Sushan|\n",
            "|      8|   Rajni|\n",
            "|      9|  Rajesh|\n",
            "|     10| Prateek|\n",
            "+-------+--------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "user_data = [\n",
        "    (1, \"Darshan\"),\n",
        "    (2, \"Mukund\"),\n",
        "    (3, \"Raj\"),\n",
        "    (4, \"Sadiksha\"),\n",
        "    (5, \"Kushal\"),\n",
        "    (6, \"Himanshu\"),\n",
        "    (7, \"Sushan\"),\n",
        "    (8, \"Rajni\"),\n",
        "    (9, \"Rajesh\"),\n",
        "    (10, \"Prateek\")\n",
        "]\n",
        "\n",
        "user_schema = [\"user_id\", \"name\"]\n",
        "user_data_df = spark.createDataFrame(user_data,user_schema)\n",
        "user_data_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+------+\n",
            "|user_id|rating|\n",
            "+-------+------+\n",
            "|      1|     7|\n",
            "|      2|     7|\n",
            "|      3|     5|\n",
            "|      4|     9|\n",
            "|      5|     7|\n",
            "|      6|     5|\n",
            "|      7|     6|\n",
            "|      8|     5|\n",
            "|      9|     8|\n",
            "|     10|     6|\n",
            "+-------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "user_ratings_data = [\n",
        "    (1, 7),\n",
        "    (2, 7),\n",
        "    (3, 5),\n",
        "    (4, 9),\n",
        "    (5, 7),\n",
        "    (6, 5),\n",
        "    (7, 6),\n",
        "    (8, 5),\n",
        "    (9, 8),\n",
        "    (10, 6)\n",
        "]\n",
        "user_ratings_schema = [\"user_id\", \"rating\"]\n",
        "user_ratings = spark.createDataFrame(user_ratings_data, user_ratings_schema)\n",
        "user_ratings.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 83:===========================================>              (3 + 1) / 4]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+--------+------+\n",
            "|user_id|    name|rating|\n",
            "+-------+--------+------+\n",
            "|      1| Darshan|     7|\n",
            "|      2|  Mukund|     7|\n",
            "|      3|     Raj|     5|\n",
            "|      4|Sadiksha|     9|\n",
            "|      5|  Kushal|     7|\n",
            "|      6|Himanshu|     5|\n",
            "|      7|  Sushan|     6|\n",
            "|      8|   Rajni|     5|\n",
            "|      9|  Rajesh|     8|\n",
            "|     10| Prateek|     6|\n",
            "+-------+--------+------+\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "combined_df = user_data_df.join(user_ratings, on=\"user_id\")\n",
        "combined_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 93:===========================================>              (3 + 1) / 4]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+--------+------+\n",
            "|user_id|    name|rating|\n",
            "+-------+--------+------+\n",
            "|      1| Darshan|     7|\n",
            "|      2|  Mukund|     7|\n",
            "|      3|     Raj|     5|\n",
            "|      4|Sadiksha|     9|\n",
            "|      5|  Kushal|     7|\n",
            "|      6|Himanshu|     5|\n",
            "|      7|  Sushan|     6|\n",
            "|      8|   Rajni|     5|\n",
            "|      9|  Rajesh|     8|\n",
            "|     10| Prateek|     6|\n",
            "+-------+--------+------+\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "#sparksql\n",
        "user_data_df.createOrReplaceTempView(\"user_table\")\n",
        "user_ratings.createOrReplaceTempView(\"user_ratings_table\")\n",
        "result_df = spark.sql(\"\"\"\n",
        "    SELECT u.user_id, u.name, r.rating\n",
        "    FROM user_table u\n",
        "    INNER JOIN user_ratings_table r\n",
        "    ON u.user_id = r.user_id\n",
        "\"\"\")\n",
        "result_df.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "DQ",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
